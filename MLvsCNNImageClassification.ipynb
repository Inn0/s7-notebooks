{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Traditional Machine learning versus Convolutional Neural Networks\n",
    "This notebook servers as a proof-of-concept for the research done for the development of the Moodboard Generator project. Within this research, traditional machine learning and cnns will be compared in usefulness for smaller datasets. The dataset that will be used is pictures of Pokemon, that will be seperated into liked and disliked classes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading the images and preparing them for use"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to dived the images, 50 images were chosen for the liked class, and 50 for the disliked. These were picked at random at first, but this made both models about 50% accurate. In order to mitigate the random selection, 50 images were manually chosen per class. This was done by selecting winged Pokemon for the liked folder, and Pokemon without wings for the disliked class. This could make it a more realistic scenario, and ensure that the models have something to go on. Do not execute the next code block."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "809\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "files_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(\"./MLvsCNNimages/images\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "            files_list.append(os.path.join(root, file))\n",
    "\n",
    "file_count = len(files_list)\n",
    "print(file_count)\n",
    "\n",
    "filesToCopyLiked = random.sample(files_list, 50)\n",
    "filesToCopyDisliked = random.sample(files_list, 50)\n",
    "\n",
    "destPathLiked = \"./MLvsCNNimages/dataset/liked\"\n",
    "destPathDisliked = \"./MLvsCNNimages/dataset/disliked\"\n",
    "\n",
    "\n",
    "if not os.path.isdir(destPathLiked):\n",
    "    os.makedirs(destPathLiked)\n",
    "\n",
    "if not os.path.isdir(destPathDisliked):\n",
    "    os.makedirs(destPathDisliked)\n",
    "\n",
    "for file in filesToCopyLiked:\n",
    "    shutil.copy(file, destPathLiked)\n",
    "\n",
    "for file in filesToCopyDisliked:\n",
    "    shutil.copy(file, destPathDisliked)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, let's see if everything is in order by seeing how many images are in both folders."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disliked images: 94\n",
      "Liked images: 98\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "files_list = []\n",
    "for root, dirs, files in os.walk(\"./MLvsCNNimages/dataset/disliked\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "            files_list.append(os.path.join(root, file))\n",
    "\n",
    "file_count = len(files_list)\n",
    "print(\"Disliked images: \" + str(file_count))\n",
    "\n",
    "files_list = []\n",
    "for root, dirs, files in os.walk(\"./MLvsCNNimages/dataset/liked\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") or file.endswith(\".png\") or file.endswith(\".jpeg\"):\n",
    "            files_list.append(os.path.join(root, file))\n",
    "\n",
    "file_count = len(files_list)\n",
    "print(\"Liked images: \" + str(file_count))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import the images as dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 12:51:32.878662: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 12:51:33.835893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-13 12:51:33.835972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-13 12:51:34.014913: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_dir = \"./MLvsCNNimages/dataset\"\n",
    "\n",
    "batch_size = 10\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspecting some images"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configure the dataset for performance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traditional Machine learning model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(val_ds, verbose=2)\n",
    "print('\\nTest accuracy:', str(test_acc * 100) + \"%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Neural Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names))\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(val_ds, verbose=2)\n",
    "print('\\nTest accuracy:', str(test_acc * 100) + \"%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results\n",
    "With random images (3-25 epochs): ML = 50%, CNN = 50%\n",
    "With picked images (5 epochs): ML = 75%, CNN = 50%\n",
    "With picked images (10 epochs): ML = 90%, CNN = 80%\n",
    "With picked images (25 epochs): ML = 90%, CNN = 85%"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
